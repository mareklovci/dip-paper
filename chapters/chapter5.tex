\chapter{Conclusion and future work}\label{ch:conclusion-and-future-work}

\section{Future work}\label{sec:future-work}

We opened many topics in the paper but were unable to explore them in depth.
There are numerous ways in which the paper could be improved.

One topic that deserves more attention is the issue of data quality in relation to security constraints.
As discussed in Section~\ref{sec:data-quality-and-security}, data security and anonymization algorithms have an impact on data quality.
It would be interesting to measure the influence of these algorithms and compare them to reports on unclassified data in future work.

The use of quantitative methods for evaluating the quality of datasets is the second topic that was not sufficiently researched in the work.
Quantitative dimensions of quality were partially examined in the Section~\ref{sec:data-quality-dimensions}.
These dimensions were even put to the test on a portion of the data catalog.
However, the approach proved to be a dead end during the writing of the work because we couldn't objectively assess the current state of quality of the data catalog based on the measured values.

\section{Conclusion}\label{sec:conclusion}

The subject of data quality is extremely broad and diverse.
Although it may appear to be sufficiently researched at first glance, the application of specific (often very abstract) methodologies proves to be very problematic in practice.
It is necessary to ensure a~certain level of data source quality.
Whether it is for the needs of the company's management or for the needs of a machine learning algorithm.

The first contribution of this work is the definition of a new methodology for evaluating the quality of datasets, as well as the presentation of its application on three examples across the data centralization spectrum.
The second and most important contribution of this work is the evaluation of the catalog's quality using COVID-19 data from the Institute of Health Information and Statistics of the Czech Republic.
The analysis was evaluated within the framework of the methodology that we defined.

We attempted an objective evaluation of the data catalog.
However, because a~portion of the questionnaire used could not be answered, a correction by a specialist in the field would be appropriate.
This, however, does not diminish the importance of our work, which can now serve as a standard against which future work can be measured.
It is critical to perform repeated evaluations in order to gradually improve data quality.
However, due to the time consuming nature of such work, part of the process would need to be automated.
