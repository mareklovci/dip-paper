\chapter{Introduction}\label{ch:introduction}

Today, we live in what many refer to as the Information Age, in which digital data production is central to all ecosystems.
Data is being used to drive growth in businesses of all sizes, large and small.
All industries require the use of data to analyze, manage, and control various systems.
Decisions based on data are a rapidly growing phenomenon in the business world.
And now, with the data, a business owner or manager can make more effective strategic decisions~\cite{chaudhuri2011}.
Making decisions can be risky at times due to the possibility of inaccurate or insufficient data.
However, because the data is unstructured and complex, maintaining and governing it is critical for organizations~\cite{blumberg2003}.
But how can we be certain that the data is objectively correct?

As Orr (1998) stated,
\blockquote[][]{data quality is the measure of the agreement between the data views presented by an information system and the same data in the real world.
A~system's data quality of 100\% would indicate, for example, that our data views are in perfect agreement with the real world, whereas a data quality rating of 0\% would indicate no agreement at all~\cite{orr1998}.}

Assuring a certain level of data quality is a standard IT project.
There are some initiatives for improving Open Data Quality, such as 5 Star Data, but none of them are comprehensive.
In short, objectively assessing data quality is difficult.

The main issue with this topic is that data quality is shrouded in misconceptions.
Data quality is a business issue, not an IT issue.
However, IT enables the business to improve itself by providing tools and processes.
Bad data has an impact on every system and every person who interacts with it.
As a result, it should be everyone's responsibility to uphold good standards and practices, which will increase trust in data used for reporting and analytics.

There are two major reasons for Data Quality Management implementation failure.
The first one is related to a~lack of data quality processes, such as a~lack of proactive DQ surveillance~\cite{risto2011}.
The second is a~scarcity of data quality measurements~\cite{haug2013}.

% Data Quality Assessment (DQA) and Master Data Management (MDM) are both connected to assuring level of DQ, in this body of work we are going to use them interchangeably.

The cost of bad data is defined as \textit{direct} + \textit{indirect} costs.
Manual and automatic master data cleaning incurs direct costs.~\cite{haug2013}.
Indirect cost, on the other hand, is financial loss caused by poor-quality master data which leads to
\begin{enumerate*}[label=(\roman*)]
    \item inadequate managerial decision,
    \item process failure and
    \item missed opportunity~\cite{haug2013}.
\end{enumerate*}

Despite the fact that the goal of data quality assessment is to reduce \textit{costs} and \textit{complexity}, the data quality process can still result in low quality master data.
The typical perpetrators in such cases are
\begin{enumerate*}[label=(\roman*)]
    \item lack of DQ measurements (or faulty definition) and
    \item absence of clear roles in the data life-cycle process~\cite{haug2013}.
\end{enumerate*}

The solutions to the problems mentioned above are as follows
\begin{enumerate*}[label=(\roman*)]
    \item a data model definition (metadata) and
    \item proactive data quality surveillance~\cite{risto2011}.
\end{enumerate*}

\blockquote[][]{One certain way to improve the quality of data: improve its use!}~\cite{orr1998}

\section*{Work emphasis}

There are many things that must be taken into account when implementing the DQ methodology.
To name a few~\cite{loshin2008}:
\begin{itemize}
    \item stakeholders and participants' involvement,
    \item metadata management,
    \item architecture styles,
    \item functional services,
    \item data modeling,
    \item data consolidation and integration,
    \item management guidance,
    \item master data identification and
    \item master data synchronization.
\end{itemize}

Batini et al. (2009) recognized activities of data quality methodology.
In the most general case, the list is composed of four phases listed below~\cite{batini2009}.
Additional steps are defined in each of the four sections, but we will not go over them in detail here.
\begin{enumerate}
    \item \textit{State reconstruction}, which is aimed to get information about business processes and services, data collection, quality issues, and corresponding costs.
    \item \textit{Measurement}, where the objective is to measure the quality of data collection along relevant quality dimensions.
    \item \textit{Assessment}, which refers to the event when \textit{measurements} are compared with certain reference values to determine the state of quality and to assess the causes of poor data.
    \item \textit{Improvement} concerns the selection of the steps, strategies, and techniques for reaching new data quality targets.
\end{enumerate}

To narrow the scope, this thesis will concentrate on these components in order to achieve a good and reasonable goal within a limited time and resource:
\begin{enumerate*}[label=(\roman*)]
    \item Definition of Data Quality Methodology and
    \item Data Quality Score Measurement \& Assesment.
\end{enumerate*}

Measurement of Quality (MoQ) is part of the \textit{measurement phase}.
The idea is to select the quality dimensions affected by the quality issues identified in the DQ requirements analysis and define corresponding metrics~\cite{loshin2008}.
Measurement can be objective when it is based on quantitative metrics, or subjective, when it is based on qualitative evaluations by data administrators and users~\cite{loshin2008}.

To complete this assignment, we will concentrate on automatic assessment of the final dataset score and define a procedure to objectively evaluate the quality score of the given dataset.
As a result, we will be able to assign a score to the dataset, giving us an idea of its current qualitative state.
Fully automatic evaluation of Quality Scores will not be possible, as we will see in Chapters~\ref{ch:quality-classification-system} and~\ref{ch:case-study}.
Therefore, we will use a semi-automatic approach, in which we will evaluate the qualitative foundation of the dataset, but subsequent levels will be evaluated automatically using the \enquote{drill-up} approach.

\section*{Research Purpose}

Data quality is a never-ending topic of discussion and is critical in a variety of fields, including telecommunications, healthcare, manufacturing, banking, and insurance, among others.
There are numerous characteristics and methodologies that contribute to good data quality, and they vary depending on the domain, with certain data characteristics being more important than others.
The goal of this research is to understand the characteristics that contribute to data quality in any domain.

The primary research goal of this study is to define and apply methodology for assessing data quality, as well as to identify, collect, analyze, and evaluate quality metrics for data in order to quantify and improve their value.
To suit the specifics of our case study in the Chapter~\ref{ch:case-study}, we will select the principal characteristics that contribute to data quality in the field of selected data.
The quality metrics chosen should be those that objectively quantify data value.

We will use and assess data from the (currently ongoing) COVID-19 pandemic.
The reason for the selection is the general availability, large collection, and open license of selected datasets.
